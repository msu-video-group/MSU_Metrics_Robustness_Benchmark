{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8c5c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name = 'maniqa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623b37f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_path = f'./subjects/{metric_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1b9742",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git submodule update --init --recursive --depth=1 {metric_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25101e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd {metric_path} && docker build --tag {metric_name} ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49408447",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_list = [\n",
    "    'korhonen-et-al',\n",
    "    'madc',\n",
    "    'amifgsm',\n",
    "    'mifgsm',\n",
    "    'ifgsm',\n",
    "    'std-fgsm',\n",
    "    'cumulative-uap',\n",
    "    'uap',\n",
    "    'generative-uap'\n",
    "]\n",
    "trainable_attacks = [\n",
    "    'cumulative-uap',\n",
    "    'uap',\n",
    "    'generative-uap'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e9c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "should_train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4c2564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aebee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{metric_path}/config.json') as json_file:\n",
    "        config = json.load(json_file)\n",
    "        metric_model = config['weight']\n",
    "        module = config['module']\n",
    "        is_fr = config['is_fr']\n",
    "quality_param = '--jpeg-quality 80' if is_fr else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7954185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_STORAGE = os.path.abspath('./data')\n",
    "RESULTS_STORAGE = os.path.abspath('./res')\n",
    "utils_path = os.path.abspath(fr'./methods/utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7828405",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = ' '.join(['VOC2012', 'COCO'])\n",
    "train_datasets_paths = ' '.join(['/train/VOC2012', '/train/COCO_train_9999'])\n",
    "test_datasets = ' '.join(['NIPS', 'DERF', 'VIMEO'])\n",
    "test_datasets_paths = ' '.join(['/test/NIPS2017', '/test/DERF_blue_sky', '/test/vimeo_test_2001'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcd75c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for attack_name in attack_list:\n",
    "    print(attack_name) \n",
    "    attack_path = os.path.abspath(fr'./methods/{attack_name}/')\n",
    "    !cd {attack_path} && docker build -t {attack_name}:{metric_name} --build-arg METRIC_IMAGE={metric_name} .\n",
    "    if attack_name in trainable_attacks:\n",
    "        if should_train:\n",
    "            print('train')\n",
    "            !docker run --gpus device=0 -i --rm \\\n",
    "              -v {DATASETS_STORAGE}:\"/train\":ro \\\n",
    "              -v {RESULTS_STORAGE}:\"/artifacts\" \\\n",
    "              -v {attack_path}/train.py:\"/train.py\" \\\n",
    "              -v {utils_path}/bounds.json:\"/bounds.json\" \\\n",
    "              -v {utils_path}/evaluate.py:\"/evaluate.py\" \\\n",
    "              -v {utils_path}/metrics.py:\"/metrics.py\" \\\n",
    "              -v {utils_path}/read_dataset.py:\"/read_dataset.py\" \\\n",
    "              {attack_name}:{metric_name} \\\n",
    "              python /train.py \\\n",
    "                --batch-size 1 \\\n",
    "                --path-train {train_datasets_paths} \\\n",
    "                --metric  {metric_name} \\\n",
    "                --train-dataset {train_datasets} \\\n",
    "                --save-dir /artifacts \\\n",
    "                {quality_param} \\\n",
    "                --device \"cuda:0\"\n",
    "            for train_dataset in train_datasets.split():\n",
    "                os.rename(\n",
    "                    os.path.join(RESULTS_STORAGE, f'{train_dataset}.npy'),\n",
    "                    os.path.join(RESULTS_STORAGE, f'{attack_name}_{metric_name}_{train_dataset}.npy')\n",
    "                )\n",
    "                os.rename(\n",
    "                    os.path.join(RESULTS_STORAGE, f'{train_dataset}.png'),\n",
    "                    os.path.join(RESULTS_STORAGE, f'{attack_name}_{metric_name}_{train_dataset}.png')\n",
    "                )\n",
    "        print('test')\n",
    "        \n",
    "        uap_paths = ' '.join([\n",
    "            f'/artifacts/{attack_name}_{metric_name}_{train_dataset}.npy'\n",
    "            for train_dataset in train_datasets.split()\n",
    "        ])\n",
    "        !docker run --gpus device=0 -i --rm \\\n",
    "          -v {DATASETS_STORAGE}:\"/test\":ro \\\n",
    "          -v {RESULTS_STORAGE}:\"/artifacts\" \\\n",
    "          -v {attack_path}/run.py:\"/run.py\" \\\n",
    "          -v {utils_path}/bounds.json:\"/bounds.json\" \\\n",
    "          -v {utils_path}/evaluate.py:\"/evaluate.py\" \\\n",
    "          -v {utils_path}/metrics.py:\"/metrics.py\" \\\n",
    "          -v {utils_path}/read_dataset.py:\"/read_dataset.py\" \\\n",
    "          {attack_name}:{metric_name} \\\n",
    "          python /run.py \\\n",
    "            --amplitude 0.2 0.4 0.8 \\\n",
    "            --metric  {metric_name} \\\n",
    "            --uap-path {uap_paths} \\\n",
    "            --train-dataset {train_datasets} \\\n",
    "            --test-dataset {test_datasets} \\\n",
    "            --dataset-path {test_datasets_paths} \\\n",
    "            {quality_param} \\\n",
    "            --save-path /artifacts/{attack_name}_{metric_name}_test.csv \\\n",
    "            --device \"cuda:0\"\n",
    "    else:\n",
    "        print('test')\n",
    "        !docker run --gpus device=0 -i --rm \\\n",
    "          -v {DATASETS_STORAGE}:\"/test\":ro \\\n",
    "          -v {RESULTS_STORAGE}:\"/artifacts\" \\\n",
    "          -v {attack_path}/run.py:\"/run.py\" \\\n",
    "          -v {utils_path}/bounds.json:\"/bounds.json\" \\\n",
    "          -v {utils_path}/evaluate.py:\"/evaluate.py\" \\\n",
    "          -v {utils_path}/metrics.py:\"/metrics.py\" \\\n",
    "          -v {utils_path}/read_dataset.py:\"/read_dataset.py\" \\\n",
    "          {attack_name}:{metric_name} \\\n",
    "          python /run.py \\\n",
    "            --test-dataset {test_datasets} \\\n",
    "            --metric  {metric_name} \\\n",
    "            --dataset-path {test_datasets_paths} \\\n",
    "            {quality_param} \\\n",
    "            --save-path /artifacts/{attack_name}_{metric_name}_test.csv \\\n",
    "            --device \"cuda:0\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e902667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c653a46f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
